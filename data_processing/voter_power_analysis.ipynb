{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Minute Moneyball: Maximize Your Impact Before Election Day\n",
    "## Author: Eric Bolton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: This notebook and analysis were first written in the aftermath of the 2018 midterm elections, as reflected in the accompanying text. However, the latest outputs reflect data from the 2020 general election.**\n",
    "\n",
    "Many reasons exist to exercise one's right to vote. Beyond simply fulfilling one's civic duty, voting constitutes a way to make one's voice heard, to feel part of something bigger, and to participate in the great democratic experiment. One might want to vote simply because increased turnout [affects policy outcomes](http://www.nyu.edu/gsas/dept/politics/seminars/hajnal_s06.pdf).\n",
    "\n",
    "Yet, every election cycle in America, tens of millions of eligible voters stay at home. It's easy to see why: in elections where hundreds of thousands vote - sometimes millions - the perception may be that one's voice is likely to be lost in the cacophony of the crowd, providing little motivation to head to the polls. One might argue that one's vote only truly \"counts\" if their vote is the one to push their candidate of choice over the brink, an event that many see as far too unlikely to warrant a visit to the voting booth.\n",
    "\n",
    "But this perception may be misguided. Consider this: if each vote has only a one in ten million chance of changing the outcome of an election, but that election affects billions of dollars in spending at a national scale, then each vote is effectively \"worth\" hundreds of dollars. In this light, voting is a rational decision per se, if only as an act of charity. This is the argument made by renowned statistician [Andrew Gelman](https://80000hours.org/2016/11/why-the-hour-you-spend-voting-is-the-most-socially-impactful-of-all/).\n",
    "\n",
    "So, using this reasoning, how much is one's vote truly worth? This project seeks to answer that in the context of the 2018 Midterm Elections for the House and Senate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Elections\n",
    "\n",
    "In order to come up with an answer, we first need to discover the likelihood that one's vote would have changed the outcome of individual races. Leading up to Election Day, this perceived likelihood depended on two key factors: what the polls were saying about each race (closer races, and more uncertain races have higher odds of being decided by one vote) and what kind of turnout is expected (races with fewer voters have higher odds of being decided by one vote). To this end, I designed a `Country` object that would read and organize the relevant data\\* into `State` objects, which in turn were associated with `Race` objects.\n",
    "\n",
    "\\*Available in the [Github repository](https://github.com/edbltn/voter-power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import elections\n",
    "\n",
    "# Create national election predictor\n",
    "country = elections.Country('../data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I looked at the polls for each race leading up to Election Day. I only considered polls that were taken during October or November\\*. Here I assumed that races with no such polls available were essentially uncontested - an assumption that held true in a vast majority of cases, but that definitely weakens the analysis. Follow up work should seek to use voting history for counties as a predictor for races where polling data was lacking.\n",
    "\n",
    "My next assumption was that the number of polling respondents favoring a given candidate would follow a Binomial distribution $B(n, p)$ where $n$ is the number of polling samples and $p$ is the probability of any voter casting a vote for the given candidate. I approximated this distribution as a Normal distribution with mean $n\\hat{p}$ and variance $n\\hat{p}(1-\\hat{p})$ where $\\hat{p}$ was the observed proportion of polling respondents favoring the given candidate.\n",
    "\n",
    "I used a truncated distribution (`scipy.stats.truncnorm`) to ensure that it would only include values between 0 and $n$. Dividing by $n$, this yielded a distribution for $p$, the probability that any voter would pick the given candidate, based on polling data:\n",
    "\n",
    "$\n",
    "p\\sim N_0^{1}\\left(\\hat{p},\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\right)\n",
    "$\n",
    "\n",
    "Where $N_0^1$ designates a truncated normal distribution between 0 and 1. We'll use $N_0^1$ as a shorthand for the above expression going forward.\n",
    "\n",
    "Let $V$ be the number of votes cast for the given candidate. Now, for a given turnout $t$, the probability that exactly $k = \\left\\lceil\\frac{t}{2}\\right\\rceil$ voters would pick the given candidate (hence - all votes are \"decisive,\" assuming a two-candidate election), would be:\n",
    "\n",
    "$\n",
    "P[V = k]_{p\\sim N_0^1} = \\left({t \\atop k}\\right)p^k(1-p)^{t-k}\n",
    "$\n",
    "\n",
    "Thus the expected tipping point probability can be computed by integrating over $N_0^1$.\n",
    "\n",
    "$\n",
    "\\mathbb{E}[P[V=k]]_{p\\sim N_0^1} = \\int_{0}^1 \\left({t \\atop k}\\right)p^k(1-p)^{t-k}N_0^1(p)dp\n",
    "$\n",
    "\n",
    "This can be computed using `scipy.stats.rv_continuous.expect`.\n",
    "\n",
    "Now, the only missing factor is the expected turnout. Here, I cheated a little and used the actual turnout on Election Day; future work should use projected turnout based on early vote counts and voting history.\n",
    "\n",
    "\\*Polls were obtained from [Real Clear Politics](https://www.realclearpolitics.com/elections/2018/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericbolton/voter-power/env/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:2626: IntegrationWarning: The integral is probably divergent, or slowly convergent.\n",
      "  vals = integrate.quad(fun, lb, ub, **kwds)[0] / invfac\n"
     ]
    }
   ],
   "source": [
    "district_probabilities = {}\n",
    "for state in country.states:\n",
    "    if state.postal_code == 'DC':\n",
    "        continue\n",
    "    for district in state.districts.values():\n",
    "        p = district.tipping_point_probability()\n",
    "        district_probabilities[district.code] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, only one Senate seat is contested per state. But the exits of Al Franken (D-MN) and Thad Cochran (R-MS) from the Senate required special elections in Minnesota and Mississippi. This meant that these states each had two Senate elections in 2018. For simplicity's sake, I'm picking the larger of the two probabilities in these cases.\n",
    "\n",
    "(*Note that the seats are examined in alphabetical order of their codes - i.e. 'MS' will be seen before 'MS2'*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "senate_seat_probabilities = {}\n",
    "for state in country.states:\n",
    "    for seat in state.senate_seats.values():\n",
    "        p = seat.tipping_point_probability()\n",
    "        if not seat.code.endswith('2'):\n",
    "            senate_seat_probabilities[state.postal_code] = p\n",
    "            senate_seat_probabilities[state.name] = p                        \n",
    "        else:\n",
    "            senate_seat_probabilities[seat.code] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_probabilities = {}\n",
    "for state in country.states:\n",
    "    for electors in state.electoral_college.values():\n",
    "        p = electors.tipping_point_probability()\n",
    "        ec_probabilities[electors.code] = p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Chamber Votes\n",
    "\n",
    "Now that we know the likelihood of one's vote changing the outcome for each individual race, we want to compute the likelihood of each individual race changing the outcome of key House and Senate votes. To predict the outcome of votes, I used partisanship scores available on [VoteView](https://voteview.com), which tracks the partisanship of each senator and representative based on their voting history. For candidates whose partisanship scores weren't available, I simply used the average score of elected officials from their party in their state.\n",
    "\n",
    "I created a `ChamberVote` object that looks at how Senators or Representatives actually voted on a past issue\\* in order to predict, using logistic regression, how a new class of elected officials would vote. In this example, I use the Senate vote to repeal Obamacare, which narrowly failed on July 28, 2017.\n",
    "\n",
    "\\*This data is also available via [VoteView](https://voteview.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from votes import ChamberVote\n",
    "\n",
    "vote = ChamberVote('../data/votes/obamacare_senate.csv', \n",
    "                   country.official_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all that remains to be done is to simulate different elections and use that to estimate how often the Obamacare vote would come down to just one vote in either chamber. In the past, polling has been known to exhibit a national bias of up to 2\\% toward one party or the other, so I am including a bias factor for each election cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tipping_points(ec, ec_diff):\n",
    "    sorted_ec = (\n",
    "        ec\n",
    "        .set_index(['party', 'code'])\n",
    "        .sort_values(by=['party', 'margin'])\n",
    "        .groupby('party')\n",
    "        .cumsum()[['value']]\n",
    "        .rename(columns={'value': 'reverse_total'})\n",
    "        .join(ec.set_index(['party', 'code'])[['value']])\n",
    "        .join(\n",
    "            ec\n",
    "            .set_index(['party', 'code'])\n",
    "            .sort_values(by=['party', 'margin'], ascending=False)\n",
    "            .groupby('party')\n",
    "            .cumsum()[['value']]\n",
    "            .rename(columns={'value': 'ec_total'})\n",
    "        )\n",
    "    )\n",
    "    sorted_ec['ec_diff'] = sorted_ec['ec_total'] - (sorted_ec.value.sum()/2)\n",
    "    tipping_points = (\n",
    "        sorted_ec[(sorted_ec.value > sorted_ec.ec_diff)\n",
    "                  & (sorted_ec.value > sorted_ec.reverse_total - sorted_ec.value)\n",
    "                  & (sorted_ec.ec_diff >= 0)]\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Return the state codes for all of the tipping points\n",
    "    return tipping_points.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77% (772 of 1000) |################      | Elapsed Time: 0:02:15 ETA:   0:00:38"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "n_simulations = 1000\n",
    "senate_power = defaultdict(lambda: 0)\n",
    "house_power = defaultdict(lambda: 0)\n",
    "ec_power = defaultdict(lambda: 0)\n",
    "\n",
    "p = progressbar.ProgressBar(term_width = 80)\n",
    "\n",
    "for n in p(range(n_simulations)):\n",
    "    \n",
    "    election_bias = np.random.normal(0, 0.01)\n",
    "    \n",
    "    gov = country.simulate_government(election_bias, vote)\n",
    "    senate = gov[gov.chamber == 'senate']\n",
    "    house = gov[gov.chamber == 'house']\n",
    "    ec = gov[gov.chamber == 'ec']\n",
    "\n",
    "    senate_diff = sum(senate.value[senate.party == 'R']) - sum(senate.value[senate.party == 'D'])\n",
    "    house_diff = sum(house.value[house.party == 'R']) - sum(house.value[house.party == 'D'])\n",
    "    ec_diff = sum(ec.value[ec.party == 'R']) - sum(ec.value[ec.party == 'D'])\n",
    "    senate_diff += np.sign(ec_diff) # The vice president\n",
    "\n",
    "    for code in get_tipping_points(ec, ec_diff):\n",
    "        ec_power[code] += 1 / n_simulations\n",
    "    for code in get_tipping_points(senate, senate_diff):\n",
    "        senate_power[code] += 1 / n_simulations\n",
    "    for code in get_tipping_points(house, house_diff):\n",
    "        house_power[code] += 1 / n_simulations\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "state_codes_df = pd.read_csv(os.path.join('../data/state_info', 'state_codes.csv'))\n",
    "state_codes = dict(zip(state_codes_df['postal_code'], state_codes_df['name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can combine the probability that a voter would be decisive in their race, and the probability that their candidate of choice would be decisive in their chamber, by multiplying them (assuming they represent independent events).\n",
    "\n",
    "$\n",
    "P[\\textrm{\"Voter is decisive\"} \\cap \\textrm{\"Elected Official is decisive\"}] = P[\\textrm{\"Voter is decisive\"}] \\cdot P[\\textrm{\"Elected Official is decisive\"}]\n",
    "$\n",
    "\n",
    "We can then multiply this result by the cost of Obamacare (\\$133 billion) estimated by the Congressional Budget Office. This will tell us how much each vote was worth in the 2018 election when it came to the issue of healthcare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "# Federal budget for 2019\n",
    "cost = 4.45e10\n",
    "\n",
    "senate_seats = defaultdict(lambda: [])\n",
    "senate_seat_values = {}\n",
    "for senate_seat, p in senate_seat_probabilities.items():\n",
    "    if len(senate_seat) > 2:\n",
    "        continue\n",
    "    senate_seats['state'].append(state_codes[senate_seat])\n",
    "    senate_seats['decisive_voter_probability'].append(p * senate_power[senate_seat])\n",
    "    \n",
    "    value = p * cost * senate_power[senate_seat]\n",
    "    senate_seat_values[state_codes[senate_seat]] = value\n",
    "    value_string = f'${round(value, 2):.2f}'\n",
    "    senate_seats['value_of_vote'].append(value_string)\n",
    "\n",
    "districts = defaultdict(lambda: [])\n",
    "district_values = {}\n",
    "for district, p in district_probabilities.items():\n",
    "    districts['district'].append(district)\n",
    "    districts['decisive_voter_probability'].append(p * house_power[district])\n",
    "    \n",
    "    value = p * cost * house_power[district]\n",
    "    district_values[district] = value\n",
    "    value_string = f'${round(value, 2):.2f}'\n",
    "    districts['value_of_vote'].append(value_string)\n",
    "    \n",
    "ec = defaultdict(lambda: [])\n",
    "electors_values = {}\n",
    "for electors, p in ec_probabilities.items():\n",
    "    if len(electors) > 2:\n",
    "        continue\n",
    "    ec['district'].append(state_codes[electors])\n",
    "    ec['decisive_voter_probability'].append(p * ec_power[electors]) \n",
    "    \n",
    "    value = p * cost * ec_power[electors]\n",
    "    electors_values[state_codes[electors]] = value\n",
    "    value_string = f'${round(value, 2):.2f}'\n",
    "    ec['value_of_vote'].append(value_string)\n",
    "    \n",
    "    \n",
    "senate_seats_df = pd.DataFrame.from_dict(senate_seats)\n",
    "districts_df = pd.DataFrame.from_dict(districts)\n",
    "electors_df = pd.DataFrame.from_dict(ec)\n",
    "\n",
    "display(electors_df.nlargest(10, 'decisive_voter_probability'))\n",
    "display(districts_df.nlargest(10, 'decisive_voter_probability'))\n",
    "display(senate_seats_df.nlargest(10, 'decisive_voter_probability'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_us_map import plot_districts, plot_states\n",
    "\n",
    "max_ec = max(electors_df.value_of_vote.apply(lambda r: float(r[1:])))\n",
    "max_state = max(senate_seats_df.value_of_vote.apply(lambda r: float(r[1:])))\n",
    "max_district = max(districts_df.value_of_vote.apply(lambda r: float(r[1:])))\n",
    "district_values['DCAL'] = 0\n",
    "plot_states(electors_values, 0, max_ec + 1)\n",
    "plot_states(senate_seat_values, 0, max_state + 1)\n",
    "plot_districts(district_values, 0, max_district + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "sims = 10000\n",
    "p = progressbar.ProgressBar(term_width = 80)\n",
    "voter_power = defaultdict(lambda: 0)\n",
    "\n",
    "for n in p(range(sims)):\n",
    "    election_bias = np.random.normal(0, 0.02)\n",
    "    gov = country.simulate_government(election_bias, vote)\n",
    "    gov['chamber_margin'] = np.nan\n",
    "    \n",
    "    totals = (\n",
    "        gov\n",
    "        .groupby(['chamber', 'party'])\n",
    "        .value.sum()\n",
    "        .reset_index()\n",
    "        .set_index('chamber')\n",
    "    )\n",
    "    margins = totals[totals.party == 'R'].value - totals[totals.party == 'D'].value\n",
    "    # Add VP!\n",
    "    margins.loc['senate'] += np.sign(margins.loc['ec'])\n",
    "    \n",
    "    for chamber in ('ec', 'house', 'senate'):\n",
    "        if all(margins >= 0):\n",
    "            for code in get_tipping_points(gov[gov.chamber == chamber], margins.loc[chamber]):\n",
    "                voter_power[code, chamber] += 1 / sims\n",
    "\n",
    "        elif all(margins <= 0):\n",
    "            for code in get_tipping_points(gov[gov.chamber == chamber], margins.loc[chamber]):\n",
    "                voter_power[code, chamber] += 1 / sims\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shapefiles can be found [here](https://www.census.gov/geo/maps-data/data/cbf/cbf_state.html) for the states (simply select 'Census 2000' and then select 'United States') and [here](https://koordinates.com/layer/96077-us-116th-congressional-districts/) for the districts.\n",
    "\n",
    "It's immediately striking that votes in some states had a negligible value, while votes in others were worth thousands of dollars each. Perhaps, in a better system, each vote would weigh equally. Analyses such as these show where the difference needs to be made, perhaps by working to reduce gerrymandering, or changing voting rules to make individual votes more impactful. One example might be the effort [spearheaded by Maine's 2nd](https://thehill.com/opinion/campaign/418058-maines-2nd-district-outcome-proves-value-of-ranked-choice-voting) in this election cycle to switch to a ranked choice voting system (votes in that tightly contested race, by the way, were worth \\$3,000 apiece). But beyond that, in the states and districts where voting mattered most, it is my hope that analyses such as these might cause those who stayed at home to reconsider their decision in future elections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cost = 4.45e10\n",
    "\n",
    "rows = []\n",
    "for code, p in ec_probabilities.items():\n",
    "    if len(code) > 2:\n",
    "        continue\n",
    "    power = (voter_power[code, 'ec'] * p)\n",
    "    if code == 'DC':\n",
    "        rows.append({\n",
    "            'state':  state_codes[code],\n",
    "            'decisive_voter_probability': power,\n",
    "            'value_of_vote':  f'${round(power * cost, 2):.2f}'\n",
    "        })\n",
    "        continue\n",
    "    power += (voter_power[code, 'senate'] * senate_seat_probabilities[code]) \n",
    "    power += (voter_power[code + '2', 'senate'] * senate_seat_probabilities[code + '2']) \n",
    "    rows.append({\n",
    "        'state':  state_codes[code],\n",
    "        'decisive_voter_probability': power,\n",
    "        'value_of_vote':  f'${round(power * cost, 2):.2f}'\n",
    "    })\n",
    "    \n",
    "state_df = pd.DataFrame(rows)\n",
    "state_df.sort_values(by='decisive_voter_probability', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for code, p in district_probabilities.items():\n",
    "    state = code[:2]\n",
    "    power = (voter_power[code, 'house'] * p)\n",
    "    if state in ('NE', 'ME'):\n",
    "        power += (voter_power[code.replace('E', 'ECD'), 'ec'] * ec_probabilities[state])\n",
    "    power += (voter_power[state, 'ec'] * ec_probabilities[state])\n",
    "    power += (voter_power[state, 'senate'] * senate_seat_probabilities[state])\n",
    "    rows.append({\n",
    "        'district': code,\n",
    "        'decisive_voter_probability': power,\n",
    "        'value_of_vote':  f'${round(power * cost, 2):.2f}'\n",
    "    })\n",
    "rows.append({\n",
    "    'district': 'DCAL',\n",
    "    'decisive_voter_probability': ec_probabilities['DC'],\n",
    "    'value_of_vote': f'${round(ec_probabilities[\"DC\"] * cost, 2):.2f}'\n",
    "})\n",
    "    \n",
    "district_df = pd.DataFrame(rows)\n",
    "district_df.sort_values(by='decisive_voter_probability', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, voters in many states performed a substantial act of charity simply by making their way to their local polling station. When this analysis was first performed in 2018, in the closely followed and hotly contested race between Kyrsten Sinema and Martha McSally, each vote was worth almost \\$8000, based on just one of many Senate votes. The races in Nevada and Indiana were worth thousands of dollars per vote as well.\n",
    "\n",
    "When these states voted on November 8th, 2018, millions of lives, and billions of dollars hung in the balance. Yet the states only had middling turnout, at 49.10\\%, 47.50\\%, and 46.90\\% each, compared to 50.10\\% nationally.\n",
    "\n",
    "Finally, let's see how these results look on a map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_us_map import plot_districts, plot_states\n",
    "\n",
    "max_state = max(state_df.value_of_vote.apply(lambda r: float(r[1:]))) + 1\n",
    "max_district = max(district_df.value_of_vote.apply(lambda r: float(r[1:]))) + 1\n",
    "plot_states(dict(zip(state_df.state, state_df.decisive_voter_probability * cost)), 0, max_state)\n",
    "plot_districts(dict(zip(district_df.district, district_df.decisive_voter_probability * cost)), 0, max_district)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
